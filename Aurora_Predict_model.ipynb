{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLAxzj7/9ULMWGeqQxnlCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vac1k/Aurora_Project/blob/main/Aurora_Predict_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–Ü–º–ø–æ—Ä—Ç –±—ñ–±–ª—ñ–æ—Ç–µ–∫"
      ],
      "metadata": {
        "id": "m2vorGx9XEHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lGm9dkmmROGw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import speech_recognition as sr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from docx import Document\n",
        "import gensim.downloader as api\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKNFEwE7STwC",
        "outputId": "a107b799-d65d-425e-bd02-1716586f00bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö –ø—Ä–æ —Ç–æ–≤–∞—Ä–∏"
      ],
      "metadata": {
        "id": "R0ySYoldbo2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_inventory = \"/content/–ó–∞–ª–∏—à–∫–∏ –ø–æ –¢–¢.xlsx\"\n",
        "inventory_df = pd.read_excel(file_path_inventory)"
      ],
      "metadata": {
        "id": "DY0eNAq9RW-G"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inventory_df = inventory_df.rename(columns={\n",
        "    \"–†—ñ–≤–µ–Ω—å –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó 3\": \"Category_Level3\",\n",
        "    \"–ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É\": \"Product_Full_Name\",\n",
        "    \"–ö-—Å—Ç—å –∑–∞–ª–∏—à–∫—ñ–≤ –Ω–∞ –∫—ñ–Ω–µ—Ü—å –¥–Ω—è\": \"Stock_Quantity_End_Day\",\n",
        "    \"–°–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å –∑–∞–ª–∏—à–∫—ñ–≤ –Ω–∞ –∫—ñ–Ω–µ—Ü—å –¥–Ω—è\": \"Stock_Cost_End_Day\"\n",
        "})"
      ],
      "metadata": {
        "id": "Koq-q_r-RiWg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jaHWe2YTWXKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inventory_df[\"Product_ID\"] = inventory_df[\"Product_Full_Name\"].str.extract(r'^(\\d+)')\n",
        "inventory_df[\"Product_Name\"] = inventory_df[\"Product_Full_Name\"].str.replace(r'^\\d+\\s+', '', regex=True)\n",
        "inventory_df[\"Product_ID\"] = pd.to_numeric(inventory_df[\"Product_ID\"], errors='coerce')\n",
        "inventory_df[\"Calculated_Price\"] = (inventory_df[\"Stock_Cost_End_Day\"] / inventory_df[\"Stock_Quantity_End_Day\"]).round(3)"
      ],
      "metadata": {
        "id": "R1VEs_eYRlJ8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ–¥—ñ–π —Ç–∞ —ó—Ö –∞–Ω–∞–ª—ñ–∑"
      ],
      "metadata": {
        "id": "zZzz5qF6b-7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_events_from_docx():\n",
        "    doc = Document(\"/content/12123.docx\")\n",
        "    events_dict, current_event = {}, None\n",
        "\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text = paragraph.text.strip()\n",
        "        if not text:\n",
        "            continue\n",
        "        if text[0].isdigit() and \".\" in text:\n",
        "            current_event = text.split(\". \", 1)[1]\n",
        "            events_dict[current_event] = []\n",
        "        elif current_event:\n",
        "            events_dict[current_event].append(text)\n",
        "    return events_dict\n",
        "\n",
        "events_data = load_events_from_docx()"
      ],
      "metadata": {
        "id": "5Q0qOY4SRmV_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è —Ç–æ–≤–∞—Ä—ñ–≤ –¥–ª—è AI-–ø–æ—à—É–∫—É"
      ],
      "metadata": {
        "id": "7UXpqXmRcDvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "inventory_df[\"Product_Vector\"] = inventory_df[\"Product_Name\"].apply(lambda x: ai_model.encode(x))\n",
        "\n",
        "word2vec_model = api.load(\"word2vec-ruscorpora-300\")"
      ],
      "metadata": {
        "id": "7bgPx3tURoiE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ –ø–æ–¥—ñ—î—é"
      ],
      "metadata": {
        "id": "53-fnqSjcM9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_words(word, top_n=3):\n",
        "    try:\n",
        "        return [w[0] for w in word2vec_model.most_similar(word, topn=top_n)]\n",
        "    except KeyError:\n",
        "        return []\n",
        "\n",
        "def filter_by_event(event_name):\n",
        "    allowed_keywords = events_data.get(event_name, [])\n",
        "    if not allowed_keywords:\n",
        "        return pd.DataFrame(columns=inventory_df.columns)\n",
        "\n",
        "    filtered_df = inventory_df[inventory_df[\"Product_Name\"].apply(\n",
        "        lambda x: any(word.lower() in x.lower() for word in allowed_keywords)\n",
        "    )]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        return find_similar_products(event_name, top_n=5)\n",
        "\n",
        "    return filtered_df.head(5)"
      ],
      "metadata": {
        "id": "8HbkxODpRqf3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI-–ø–æ—à—É–∫ —Ç–æ–≤–∞—Ä—ñ–≤"
      ],
      "metadata": {
        "id": "T9WQQekucUyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_products(query, top_n=5):\n",
        "    query_vector = np.array(ai_model.encode(query)).reshape(1, -1)\n",
        "    product_vectors = np.array(list(inventory_df[\"Product_Vector\"]))\n",
        "\n",
        "    similarity_scores = cosine_similarity(query_vector, product_vectors).flatten()\n",
        "    top_indices = similarity_scores.argsort()[-top_n:][::-1]\n",
        "\n",
        "    return inventory_df.iloc[top_indices][[\"Product_Name\", \"Category_Level3\", \"Stock_Quantity_End_Day\"]].head(top_n)"
      ],
      "metadata": {
        "id": "ac23xykkRvAa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speech Recognition"
      ],
      "metadata": {
        "id": "5LWzLRx0ch06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_speech():\n",
        "    recognizer = sr.Recognizer()\n",
        "    try:\n",
        "        with sr.Microphone() as source:\n",
        "            audio = recognizer.listen(source)\n",
        "            return recognizer.recognize_google(audio, language=\"uk-UA\")\n",
        "    except (sr.UnknownValueError, sr.RequestError, OSError):\n",
        "        return None"
      ],
      "metadata": {
        "id": "agczuc42RzA5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–∏"
      ],
      "metadata": {
        "id": "eya9HalBcnPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_user_query(user_input):\n",
        "    user_input = user_input.lower().strip()\n",
        "    matched_event = next((event for event in events_data if event.lower() in user_input), None)\n",
        "\n",
        "    if matched_event:\n",
        "        return filter_by_event(matched_event)\n",
        "\n",
        "    expanded_keywords = user_input.split()\n",
        "    for word in user_input.split():\n",
        "        expanded_keywords.extend(find_similar_words(word))\n",
        "\n",
        "    return find_similar_products(\" \".join(expanded_keywords), top_n=5)"
      ],
      "metadata": {
        "id": "izDf2bhCRx64"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    mode = input(\"üîπ –í–∏–±–µ—Ä—ñ—Ç—å —Ä–µ–∂–∏–º (1 - —Ç–µ–∫—Å—Ç–æ–≤–∏–π –≤–≤–æ–¥, 2 - –≥–æ–ª–æ—Å–æ–≤–∏–π –≤–≤–æ–¥): \").strip()\n",
        "    user_query = input(\"‚úç –í–≤–µ–¥—ñ—Ç—å –≤–∞—à –∑–∞–ø–∏—Ç: \") if mode == \"1\" else recognize_speech()\n",
        "    if not user_query:\n",
        "        return\n",
        "\n",
        "    recommendations = process_user_query(user_query)\n",
        "    print(f\"üìå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –∑–∞–ø–∏—Ç—É '{user_query}':\")\n",
        "    print(recommendations.to_string(index=False))"
      ],
      "metadata": {
        "id": "HbW9YYxKR20q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6YO3gT0R4j2",
        "outputId": "aeae5dbf-a19d-4e27-bb2d-67a76ab1c77f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ –í–∏–±–µ—Ä—ñ—Ç—å —Ä–µ–∂–∏–º (1 - —Ç–µ–∫—Å—Ç–æ–≤–∏–π –≤–≤–æ–¥, 2 - –≥–æ–ª–æ—Å–æ–≤–∏–π –≤–≤–æ–¥): 1\n",
            "‚úç –í–≤–µ–¥—ñ—Ç—å –≤–∞—à –∑–∞–ø–∏—Ç: —è —Ö–æ—á—É –ø–æ–¥–∞—Ä—É–≤–∞—Ç–∏ —â–æ—Å—å –±–∞—Ç—å–∫—É –¥–ª—è —Ä–∏–±–∞–ª–∫–∏\n",
            "üìå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –∑–∞–ø–∏—Ç—É '—è —Ö–æ—á—É –ø–æ–¥–∞—Ä—É–≤–∞—Ç–∏ —â–æ—Å—å –±–∞—Ç—å–∫—É –¥–ª—è —Ä–∏–±–∞–ª–∫–∏':\n",
            "                                         Product_Name          Category_Level3  Stock_Quantity_End_Day\n",
            "–°–Ω–∞—Å—Ç—å —Ä–∏–±–æ–ª–æ–≤–Ω–∞ —Ñ—ñ–¥–µ—Ä–Ω–∞ –¥–ª—è –ª–æ–≤–ª—ñ –∫–æ—Ä–æ–ø–∞ \"Fisherman\"   29.6 —Ä–∏–±–∞–ª—å—Å—å–∫—ñ —Å–Ω–∞—Å—Ç—ñ                       6\n",
            "   –°–Ω–∞—Å—Ç—å —Ä–∏–±–æ–ª–æ–≤–Ω–∞ –≥–æ–¥—ñ–≤–Ω–∏—Ü—è –∑ –≤—ñ–¥–≤–æ–¥–∞–º–∏ \"Fisherman\"   29.6 —Ä–∏–±–∞–ª—å—Å—å–∫—ñ —Å–Ω–∞—Å—Ç—ñ                       8\n",
            "     –ù–∞–±—ñ—Ä –ø–æ–≤—ñ–¥—Ü—ñ–≤ –¥–ª—è —Ä–∏–±–æ–ª–æ–≤–ª—ñ Fisherman –∞—Ä—Ç.50531 29.9 —Ä–∏–±–∞–ª—å—Å—å–∫–µ –ø—Ä–∏–ª–∞–¥–¥—è                      11\n",
            "         –°–Ω–∞—Å—Ç—å —Ä–∏–±–æ–ª–æ–≤–Ω–∞ —Ñ—ñ–¥–µ—Ä–Ω–∞ Fisherman –∞—Ä—Ç.50488   29.6 —Ä–∏–±–∞–ª—å—Å—å–∫—ñ —Å–Ω–∞—Å—Ç—ñ                      11\n",
            "                        –ü—Ä–∏–∫–æ—Ä–º–∫–∞ —Ä–∏–±–æ–ª–æ–≤–Ω–∞ Best –ê–Ω—ñ—Å  29.2 –ø—Ä–∏–º–∞–Ω–∫–∏,–ø—Ä–∏–∫–æ—Ä–º–∫–∏                       6\n"
          ]
        }
      ]
    }
  ]
}